{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рекомендации товаров\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "\n",
    "   * Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "   * Если товар не встречался в обучающей выборке, его популярность равна 0.\n",
    "   * Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "   * Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k.\n",
    "   \n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   \n",
    "Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "\n",
    "* сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "* сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "\n",
    "\n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k\n",
    "\n",
    "\n",
    "Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import OrderedDict, Counter\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'ranking_goods.ipynb',\n",
       " 'sessions_test.txt',\n",
       " 'sessions_train.txt',\n",
       " 'task1.txt',\n",
       " 'task2.txt',\n",
       " 'task3.txt',\n",
       " 'task4.txt',\n",
       " '__pycache__']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    \"\"\"\n",
    "    Выполнить обработку логов.\n",
    "    Сформировать массив значений Mx2, где M-одна сессия, 0 столбец-просмотры, 1 столбец-заказы.\n",
    "    \"\"\"\n",
    "    data = [x.replace('\\n', '').split(';') for x in data]\n",
    "    data = [[x[0].split(','), x[1].split(',')] for x in data]\n",
    "    for session_id in range(len(data)):\n",
    "        data[session_id][0] = [int(x) for x in data[session_id][0]]\n",
    "        if data[session_id][-1] == ['']:\n",
    "            data[session_id][-1] = []\n",
    "        else:\n",
    "            data[session_id][-1] = [int(x) for x in data[session_id][-1]]\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sessions_train.txt') as f:\n",
    "    train_data = f.readlines()\n",
    "train_array = preprocess_data(train_data)\n",
    "\n",
    "with open('sessions_test.txt') as f:\n",
    "    test_data = f.readlines()\n",
    "test_array = preprocess_data(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчет частот по просмотрам и заказам по обучающему множеству:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_id_frequency(array):\n",
    "    goods_frequency = Counter()\n",
    "    for row in array:\n",
    "        goods_frequency.update(Counter(row))\n",
    "    return goods_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "views_frequency = count_id_frequency(train_array[:, 0])\n",
    "purchases_frequency = count_id_frequency(train_array[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сессии, в которых пользователь ничего не купил, исключаем из оценки качества."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_array = np.array([x for x in train_array.tolist() if len(x[1]) > 0])\n",
    "test_array = np.array([x for x in test_array.tolist() if len(x[1]) > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 68, 67]),\n",
       "        list([67, 60, 63])],\n",
       "       [list([84, 85, 86, 87, 88, 89, 84, 90, 91, 92, 93, 86]),\n",
       "        list([86])],\n",
       "       [list([138, 198, 199, 127]), list([199])],\n",
       "       ...,\n",
       "       [list([64552, 25931, 2807]), list([25935, 2807])],\n",
       "       [list([91921, 20251, 5063, 21742, 5063, 20251, 34927]),\n",
       "        list([91921])],\n",
       "       [list([32291, 60520, 32291, 38220]), list([32291])]], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[list([63, 68, 69, 70, 66, 61, 59, 61, 66, 68]), list([66, 63])],\n",
       "       [list([158, 159, 160, 159, 161, 162]), list([162])],\n",
       "       [list([200, 201, 202, 203, 204]), list([201, 205])],\n",
       "       ...,\n",
       "       [list([60538, 44430, 66252, 44430, 60538, 66251]),\n",
       "        list([66252, 44430])],\n",
       "       [list([49815, 76363]), list([49815])],\n",
       "       [list([21841, 17711, 21841, 17711, 21841, 17711, 21841, 17711, 22562, 17711, 21841]),\n",
       "        list([21841])]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3608, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3665, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_duplicates(l):\n",
    "    \"\"\"\n",
    "    Очистить список от дубликатов. При этом сохранить порядок.\n",
    "    Дубликаты могут быть налюбом расстоянии друг от друга.\n",
    "    \"\"\"\n",
    "    new_l = []\n",
    "    for x in l:\n",
    "        if x in new_l:\n",
    "            pass\n",
    "        else:\n",
    "            new_l.append(x)\n",
    "    return new_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[59, 60, 61, 62, 60, 63, 64, 65, 66, 61, 67, 68, 67]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_array[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(frequency_dict, views, k):\n",
    "\n",
    "    #unique_views = clear_duplicates(views)\n",
    "    unique_views = list(OrderedDict.fromkeys(views))\n",
    "    \n",
    "    if len(unique_views) < k:\n",
    "        recomend_list = unique_views\n",
    "    else:\n",
    "        df = pd.DataFrame({'id': unique_views,\n",
    "                           'position': [i for i in range(len(unique_views))],\n",
    "                           'frequency': [frequency_dict[x] for x in unique_views],\n",
    "                         } \n",
    "                         )\n",
    "        df.sort_values(['frequency', 'position'], ascending=[False, True], kind='mergesort', inplace=True)\n",
    "        recomend_list = df['id'].tolist()[:k]\n",
    "        \n",
    "    return recomend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63, 64, 60, 61, 65]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(views_frequency, train_array[0][0], 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[63]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend(views_frequency, train_array[0][0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(recomends, orders, k):\n",
    "    if len(orders)==0:\n",
    "        return {'precision': 0,\n",
    "                'recall': 0\n",
    "           }\n",
    "    else:\n",
    "        c = len(set(recomends).intersection(set(orders)))\n",
    "        return {'precision': c/k,\n",
    "                'recall': c/len(orders)\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(dataset, frequency_dict):\n",
    "    for k in [1, 5]:\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        for i in range(len(dataset)):\n",
    "            \n",
    "            views, orders = dataset[i][0], dataset[i][1]\n",
    "            recomendation = recommend(frequency_dict, views, k)\n",
    "\n",
    "            metrcis = get_metrics(recomendation, orders, k)\n",
    "            precision_list.append(metrcis['precision'])\n",
    "            recall_list.append(metrcis['recall'])\n",
    "\n",
    "        mean_precision = sum(precision_list)/len(dataset)\n",
    "        mean_recall = sum(recall_list)/len(dataset)\n",
    "        print(f'Recall@{k}: {mean_recall}')\n",
    "        print(f'Precision@{k}: {mean_precision}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data. Views frequency\n",
      "Recall@1: 0.4426343165949593\n",
      "Precision@1: 0.5121951219512195\n",
      "Recall@5: 0.8246918247126122\n",
      "Precision@5: 0.21252771618625918\n",
      "\n",
      "Train data. Purchases frequency\n",
      "Recall@1: 0.6884494924267653\n",
      "Precision@1: 0.8037694013303769\n",
      "Recall@5: 0.9263073024228787\n",
      "Precision@5: 0.2525498891352649\n"
     ]
    }
   ],
   "source": [
    "print('Train data. Views frequency')\n",
    "evaluate_dataset(train_array, views_frequency)\n",
    "print('\\nTrain data. Purchases frequency')\n",
    "evaluate_dataset(train_array, purchases_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data. Views frequency\n",
      "Recall@1: 0.41733266203252534\n",
      "Precision@1: 0.48130968622100956\n",
      "Recall@5: 0.8000340663538579\n",
      "Precision@5: 0.2037653478854079\n",
      "\n",
      "Test data. Purchases frequency\n",
      "Recall@1: 0.4606201666660294\n",
      "Precision@1: 0.5276944065484311\n",
      "Recall@5: 0.8201874337490194\n",
      "Precision@5: 0.21009549795362173\n"
     ]
    }
   ],
   "source": [
    "print('Test data. Views frequency')\n",
    "evaluate_dataset(test_array, views_frequency)\n",
    "print('\\nTest data. Purchases frequency')\n",
    "evaluate_dataset(test_array, purchases_frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
