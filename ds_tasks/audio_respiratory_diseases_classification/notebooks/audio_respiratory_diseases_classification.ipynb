{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20e82e9",
   "metadata": {},
   "source": [
    "### Audio-based respiratory diseases classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf15cf",
   "metadata": {},
   "source": [
    "The dataset source: [Respiratory Sound Database](https://www.kaggle.com/vbookshelf/respiratory-sound-database).\n",
    "\n",
    "The dataset: __920__ annotated wav recordings of varying length - 10s to 90s from 126 patients.\n",
    "The patients span all age groups - children, adults and the elderly.\n",
    "The wav files were taken from different lung locations and with various recording devices.\n",
    "\n",
    "In this example several audio features will be extracted first and  then deep learning model will be used as a classifier.\n",
    "All the observations will be considered as independent irrespective of patient ids. However, in fact, patient id information with lung locations can be used further to improve the model.\n",
    "\n",
    "The source code [GitHub link](https://github.com/alexander-pv/educational_repo/tree/master/ds_tasks/audio_respiratory_diseases_classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5322f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "path_append_flag = True\n",
    "if path_append_flag:\n",
    "    sys.path.append('../')\n",
    "    path_append_flag = False\n",
    "\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch .nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import librosa\n",
    "import torchaudio\n",
    "import seaborn as sns\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.dataset import RespiratoryDataset\n",
    "from src.model import RDClassifier\n",
    "from src import training\n",
    "\n",
    "sns.set()\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4d7c836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68eaf565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.9.7\n",
      "IPython version      : 7.31.0\n",
      "\n",
      "pandas    : 1.3.4\n",
      "numpy     : 1.20.3\n",
      "seaborn   : 0.11.2\n",
      "matplotlib: 3.5.0\n",
      "torch     : 1.10.1\n",
      "torchaudio: 0.10.1\n",
      "librosa   : 0.8.1\n",
      "\n",
      "Watermark: 2.3.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,seaborn,matplotlib,torch,torchaudio,librosa -vw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27af9aab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default subset classes mapping:\n",
      "{'Asthma': 0, 'Bronchiectasis': 1, 'Bronchiolitis': 2, 'COPD': 3, 'Healthy': 4, 'LRTI': 5, 'Pneumonia': 6, 'URTI': 7}\n",
      "default subset was created. Size: 920\n"
     ]
    }
   ],
   "source": [
    "dataset = RespiratoryDataset(\n",
    "    annotation_path='../data/Respiratory_Sound_Database/patient_diagnosis.csv',\n",
    "    audio_dir='../data/Respiratory_Sound_Database/audio_and_txt_files',\n",
    "    transform=None,\n",
    "    target_sample_rate=16000,\n",
    "    name='default',\n",
    "    seed=seed,\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8212f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>class_label</th>\n",
       "      <th>wav_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>130</td>\n",
       "      <td>COPD</td>\n",
       "      <td>../data/Respiratory_Sound_Database/audio_and_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>138</td>\n",
       "      <td>COPD</td>\n",
       "      <td>../data/Respiratory_Sound_Database/audio_and_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>COPD</td>\n",
       "      <td>../data/Respiratory_Sound_Database/audio_and_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>158</td>\n",
       "      <td>COPD</td>\n",
       "      <td>../data/Respiratory_Sound_Database/audio_and_t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104</td>\n",
       "      <td>COPD</td>\n",
       "      <td>../data/Respiratory_Sound_Database/audio_and_t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id class_label                                           wav_path\n",
       "0         130        COPD  ../data/Respiratory_Sound_Database/audio_and_t...\n",
       "1         138        COPD  ../data/Respiratory_Sound_Database/audio_and_t...\n",
       "2         130        COPD  ../data/Respiratory_Sound_Database/audio_and_t...\n",
       "3         158        COPD  ../data/Respiratory_Sound_Database/audio_and_t...\n",
       "4         104        COPD  ../data/Respiratory_Sound_Database/audio_and_t..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_prepared_annot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "935c1cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_label\n",
       "COPD              793\n",
       "Pneumonia          37\n",
       "Healthy            35\n",
       "URTI               23\n",
       "Bronchiectasis     16\n",
       "Bronchiolitis      13\n",
       "LRTI                2\n",
       "Asthma              1\n",
       "Name: patient_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_prepared_annot.groupby(by=['class_label'])['patient_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb73db4c",
   "metadata": {},
   "source": [
    "Unfortunately, the dataset has only 2 LRTI wav records and 1 Asthma one. These labels should be dropped.\n",
    "To deal with class-imbalance problem there are several options, for example:\n",
    "\n",
    "1. Weighted loss function.\n",
    "2. Weighted batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b5d5ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default subset classes mapping:\n",
      "{'Bronchiectasis': 0, 'Bronchiolitis': 1, 'COPD': 2, 'Healthy': 3, 'Pneumonia': 4, 'URTI': 5}\n",
      "default subset was created. Size: 917\n"
     ]
    }
   ],
   "source": [
    "dataset = RespiratoryDataset(\n",
    "    annotation_path='../data/Respiratory_Sound_Database/patient_diagnosis.csv',\n",
    "    audio_dir='../data/Respiratory_Sound_Database/audio_and_txt_files',\n",
    "    transform=None,\n",
    "    target_sample_rate=16000,\n",
    "    exclude_classes=('LRTI', 'Asthma'),\n",
    "    name='default',\n",
    "    seed=seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f702dc50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class_label\n",
       "COPD              793\n",
       "Pneumonia          37\n",
       "Healthy            35\n",
       "URTI               23\n",
       "Bronchiectasis     16\n",
       "Bronchiolitis      13\n",
       "Name: patient_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.df_prepared_annot.groupby(by=['class_label'])['patient_id'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012dcfde",
   "metadata": {},
   "source": [
    "Stratified subset split is needed for train, validation and test. Fixed seed for pseudorandom number generator prevents from subsets overlaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc51970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size = 0.7, 0.6\n",
    "n_mfcc, n_mels, n_bands = 64, 128, 6\n",
    "sample_rate = 16000\n",
    "batch_size = 32\n",
    "n_epochs = 25\n",
    "channels = 1\n",
    "features_length = sum((n_mfcc, n_mels, n_bands+1))\n",
    "exclude_classes = ('LRTI', 'Asthma')\n",
    "device = 'cuda'\n",
    "weighted_loss = False\n",
    "\n",
    "num_workers = mp.cpu_count()//2\n",
    "prefetch = 4\n",
    "\n",
    "feature_extractors = (\n",
    "    torchaudio.transforms.MFCC(sample_rate=sample_rate, n_mfcc=n_mfcc),\n",
    "    torchaudio.transforms.MelSpectrogram(\n",
    "        sample_rate=sample_rate, n_mels=n_mels),\n",
    "    lambda x: torch.Tensor(\n",
    "        librosa.feature.spectral_contrast(\n",
    "            S=np.abs(librosa.stft(x.numpy()[0])), sr=sample_rate, n_bands=n_bands)\n",
    "    ).unsqueeze(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45bfb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train subset classes mapping:\n",
      "{'Bronchiectasis': 0, 'Bronchiolitis': 1, 'COPD': 2, 'Healthy': 3, 'Pneumonia': 4, 'URTI': 5}\n",
      "train subset was created. Size: 641\n",
      "val subset classes mapping:\n",
      "{'Bronchiectasis': 0, 'Bronchiolitis': 1, 'COPD': 2, 'Healthy': 3, 'Pneumonia': 4, 'URTI': 5}\n",
      "val subset was created. Size: 165\n",
      "test subset classes mapping:\n",
      "{'Bronchiectasis': 0, 'Bronchiolitis': 1, 'COPD': 2, 'Healthy': 3, 'Pneumonia': 4, 'URTI': 5}\n",
      "test subset was created. Size: 111\n"
     ]
    }
   ],
   "source": [
    "datasets, dataloaders = {}, {}\n",
    "dataloaders = {}\n",
    "for name in ('train', 'val', 'test'):\n",
    "    datasets.update(\n",
    "        {\n",
    "            name: RespiratoryDataset(\n",
    "                annotation_path='../data/Respiratory_Sound_Database/patient_diagnosis.csv',\n",
    "                audio_dir='../data/Respiratory_Sound_Database/audio_and_txt_files',\n",
    "                transform=feature_extractors,\n",
    "                target_sample_rate=sample_rate,\n",
    "                exclude_classes=exclude_classes,\n",
    "                name=name,\n",
    "                train_size=train_size,\n",
    "                val_size=val_size,\n",
    "                seed=seed,\n",
    "\n",
    "            )\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    dataloaders.update(\n",
    "        {name: DataLoader(datasets[name],\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True,\n",
    "                         num_workers=num_workers,\n",
    "                         prefetch_factor=prefetch\n",
    "                         )\n",
    "         \n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "class_dict = datasets['train'].class_map\n",
    "obs_count = datasets['train'].subset_annotation['class_label'].value_counts(\n",
    ").to_dict()\n",
    "obs_count = {class_dict[k]: v for k, v in obs_count.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57294a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f8365715a90>,\n",
       " 'val': <torch.utils.data.dataloader.DataLoader at 0x7f8365717df0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f83656d9ac0>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1553c7a",
   "metadata": {},
   "source": [
    "Model initialization and training. By default, loss function has no weights.\n",
    "\n",
    "The number of epochs will be limited to 25 because of dataset size and Jupyter which saves epochs logs spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7e49974",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RDClassifier(input_shape=(batch_size, channels, features_length), n_classes=len(class_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685f828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_weights = training.set_weighted_loss(label_to_count=obs_count, device=device) if weighted_loss else None\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=loss_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef48aaab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.28it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: inf -> 0.827966570854187. Model was saved.\n",
      "[12.180683 sec.][Epoch 1] train_loss: 2.3886371655389667, val_loss: 0.827966570854187, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.29it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.827966570854187 -> 0.42635267972946167. Model was saved.\n",
      "[12.195124 sec.][Epoch 2] train_loss: 0.4988556755706668, val_loss: 0.42635267972946167, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.18it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.397045 sec.][Epoch 3] train_loss: 0.75326386699453, val_loss: 0.49514541029930115, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.02it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.42635267972946167 -> 0.40727174282073975. Model was saved.\n",
      "[13.366245 sec.][Epoch 4] train_loss: 0.2772985593182966, val_loss: 0.40727174282073975, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.18it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.426057 sec.][Epoch 5] train_loss: 0.4763962486758828, val_loss: 0.46971023082733154, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.13it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.40727174282073975 -> 0.32516953349113464. Model was saved.\n",
      "[12.908104 sec.][Epoch 6] train_loss: 0.22997818852309138, val_loss: 0.32516953349113464, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.05it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.32516953349113464 -> 0.3183504641056061. Model was saved.\n",
      "[13.507227 sec.][Epoch 7] train_loss: 0.20976010174490511, val_loss: 0.3183504641056061, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  1.92it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:03<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.128706 sec.][Epoch 8] train_loss: 1.6567334469873458, val_loss: 0.3954455554485321, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:11<00:00,  1.85it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.3183504641056061 -> 0.28562048077583313. Model was saved.\n",
      "[14.570497 sec.][Epoch 9] train_loss: 0.1935860259036417, val_loss: 0.28562048077583313, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.088851 sec.][Epoch 10] train_loss: 0.1764235484879464, val_loss: 0.3442363142967224, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.08it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.851225 sec.][Epoch 11] train_loss: 3.7020758234430104, val_loss: 0.3527678847312927, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  1.98it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.420935 sec.][Epoch 12] train_loss: 2.249194824602455, val_loss: 0.39600199460983276, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.14it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.592979 sec.][Epoch 13] train_loss: 0.23690630169582505, val_loss: 0.35751792788505554, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.920663 sec.][Epoch 14] train_loss: 0.9464375688694417, val_loss: 0.2891508936882019, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.13it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.605518 sec.][Epoch 15] train_loss: 0.21819687425158918, val_loss: 0.47460365295410156, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.960888 sec.][Epoch 16] train_loss: 0.1519299757637782, val_loss: 0.3634588420391083, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.11it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.756235 sec.][Epoch 17] train_loss: 0.13840530323795974, val_loss: 0.4350879192352295, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.11it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 0.28562048077583313 -> 0.21398834884166718. Model was saved.\n",
      "[13.081311 sec.][Epoch 18] train_loss: 0.11442522157449275, val_loss: 0.21398834884166718, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.13it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.579839 sec.][Epoch 19] train_loss: 0.10258940717903897, val_loss: 0.33991217613220215, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.025398 sec.][Epoch 20] train_loss: 0.07551983585290145, val_loss: 0.32219451665878296, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.989878 sec.][Epoch 21] train_loss: 0.06822906743036583, val_loss: 0.3603914678096771, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.11it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.715775 sec.][Epoch 22] train_loss: 0.31295500590931624, val_loss: 0.27668967843055725, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  1.99it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.4094 sec.][Epoch 23] train_loss: 0.12359182850923389, val_loss: 0.3752691447734833, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.064438 sec.][Epoch 24] train_loss: 0.0657175074738916, val_loss: 0.3324386477470398, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training.model_train(\n",
    "    net=model,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    save_path='../weights',\n",
    "    class_dict=class_dict,\n",
    "    model_name='rd_classifier',\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a2676c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RDClassifier(\n",
       "  (conv1): Conv1d(1, 128, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=46592, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RDClassifier(input_shape=(batch_size, channels, features_length), n_classes=len(class_dict.keys()))\n",
    "best_model.load_state_dict(torch.load(os.path.join('..', 'weights', 'pytorch_rd_classifier_epoch_18.pth')))\n",
    "best_model.to(device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1f56bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Bronchiectasis       1.00      0.50      0.67         2\n",
      " Bronchiolitis       1.00      0.50      0.67         2\n",
      "          COPD       0.98      0.99      0.98        96\n",
      "       Healthy       0.57      1.00      0.73         4\n",
      "     Pneumonia       0.75      0.75      0.75         4\n",
      "          URTI       1.00      0.33      0.50         3\n",
      "\n",
      "      accuracy                           0.95       111\n",
      "     macro avg       0.88      0.68      0.72       111\n",
      "  weighted avg       0.96      0.95      0.94       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "report_dict, report_txt = training.evaluate(best_model, dataloaders['test'], device)\n",
    "print(report_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b9a04",
   "metadata": {},
   "source": [
    "Altough the f1-score if quite high, the precision level for Healthy class is only 0.57 with recall 1.0 which means \n",
    "that lots of recordings with diseases were classified as healthy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fe8d98",
   "metadata": {},
   "source": [
    "Let's compare the model with the other one trained with weighted loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c57e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_loss = True\n",
    "model = RDClassifier(input_shape=(batch_size, channels, features_length), n_classes=len(class_dict.keys()))\n",
    "loss_weights = training.set_weighted_loss(label_to_count=obs_count, device=device) if weighted_loss else None\n",
    "criterion = torch.nn.CrossEntropyLoss(weight=loss_weights)\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2c85c20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.25it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: inf -> 1.593238353729248. Model was saved.\n",
      "[15.639461 sec.][Epoch 1] train_loss: 5.343869060277939, val_loss: 1.593238353729248, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.24it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.952528 sec.][Epoch 2] train_loss: 3.1308335959911346, val_loss: 1.7156362533569336, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.25it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.073997 sec.][Epoch 3] train_loss: 0.8634307552128888, val_loss: 1.625204086303711, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.21it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 1.593238353729248 -> 1.3312671184539795. Model was saved.\n",
      "[12.579539 sec.][Epoch 4] train_loss: 1.2088197115808725, val_loss: 1.3312671184539795, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.13it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 1.3312671184539795 -> 1.1905274391174316. Model was saved.\n",
      "[12.932196 sec.][Epoch 5] train_loss: 0.7687633177265525, val_loss: 1.1905274391174316, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.08it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.060271 sec.][Epoch 6] train_loss: 1.210467946715653, val_loss: 1.5179728269577026, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.13it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.723468 sec.][Epoch 7] train_loss: 0.6292246170341969, val_loss: 2.29421067237854, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.848886 sec.][Epoch 8] train_loss: 1.6639399891719222, val_loss: 1.6943998336791992, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.06it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.039041 sec.][Epoch 9] train_loss: 0.7450844729319215, val_loss: 1.2438884973526, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.06it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.155625 sec.][Epoch 10] train_loss: 0.5597356810467318, val_loss: 1.4617385864257812, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.09it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.87257 sec.][Epoch 11] train_loss: 0.5405278741382062, val_loss: 2.4444162845611572, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.786447 sec.][Epoch 12] train_loss: 0.5331633116584271, val_loss: 1.7160789966583252, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.961545 sec.][Epoch 13] train_loss: 0.4292934502736898, val_loss: 1.5918339490890503, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.05it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.205779 sec.][Epoch 14] train_loss: 0.3967362390831113, val_loss: 1.7146241664886475, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.045783 sec.][Epoch 15] train_loss: 0.6751249814406037, val_loss: 1.420485496520996, learning_rate: 0.001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.08it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.015201 sec.][Epoch 16] train_loss: 0.36333544133231044, val_loss: 1.7126591205596924, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.048181 sec.][Epoch 17] train_loss: 0.3200715179555118, val_loss: 1.5231831073760986, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.980816 sec.][Epoch 18] train_loss: 0.26708702580071986, val_loss: 1.4537360668182373, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:09<00:00,  2.12it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.839237 sec.][Epoch 19] train_loss: 0.37886928860098124, val_loss: 1.3515390157699585, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.08it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SaveBestModelCallback] val_loss was improved: 1.1905274391174316 -> 0.8690584897994995. Model was saved.\n",
      "[13.421531 sec.][Epoch 20] train_loss: 0.2520470902090892, val_loss: 0.8690584897994995, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.032807 sec.][Epoch 21] train_loss: 0.31553258933126926, val_loss: 1.4591901302337646, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.10it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.910144 sec.][Epoch 22] train_loss: 0.2062397941481322, val_loss: 1.473633050918579, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.07it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.90195 sec.][Epoch 23] train_loss: 0.21640073833987117, val_loss: 1.265589714050293, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 21/21 [00:10<00:00,  2.04it/s]\n",
      "100%|█████████████████████████████████████████████| 6/6 [00:02<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.275742 sec.][Epoch 24] train_loss: 4.47603911254555, val_loss: 1.5099372863769531, learning_rate: 0.0001.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training.model_train(\n",
    "    net=model,\n",
    "    train_loader=dataloaders['train'],\n",
    "    val_loader=dataloaders['val'],\n",
    "    epochs=n_epochs,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    scheduler=scheduler,\n",
    "    device=device,\n",
    "    save_path='../weights',\n",
    "    class_dict=class_dict,\n",
    "    model_name='rd_classifier',\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e39c28be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RDClassifier(\n",
       "  (conv1): Conv1d(1, 128, kernel_size=(5,), stride=(1,))\n",
       "  (conv2): Conv1d(128, 256, kernel_size=(5,), stride=(1,))\n",
       "  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv1d(256, 512, kernel_size=(5,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (linear1): Linear(in_features=46592, out_features=1024, bias=True)\n",
       "  (linear2): Linear(in_features=1024, out_features=6, bias=True)\n",
       "  (relu): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = RDClassifier(input_shape=(batch_size, channels, features_length), n_classes=len(class_dict.keys()))\n",
    "best_model.load_state_dict(torch.load(os.path.join('..', 'weights', 'pytorch_rd_classifier_epoch_20.pth')))\n",
    "best_model.to(device)\n",
    "best_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aa87bc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 4/4 [00:02<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                precision    recall  f1-score   support\n",
      "\n",
      "Bronchiectasis       0.17      0.50      0.25         2\n",
      " Bronchiolitis       0.50      0.50      0.50         2\n",
      "          COPD       0.99      0.95      0.97        96\n",
      "       Healthy       1.00      0.75      0.86         4\n",
      "     Pneumonia       0.50      0.75      0.60         4\n",
      "          URTI       1.00      0.67      0.80         3\n",
      "\n",
      "      accuracy                           0.91       111\n",
      "     macro avg       0.69      0.69      0.66       111\n",
      "  weighted avg       0.95      0.91      0.92       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "report_dict, report_txt = training.evaluate(best_model, dataloaders['test'], device)\n",
    "print(report_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d33644b",
   "metadata": {},
   "source": [
    "Now, with the weighted loss function, f1-score was reduced. However, precision and recall metrics for healthy class became more balanced. The precision is 1.0 which means that all the samples that were predicted as healthy are correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a10254",
   "metadata": {},
   "source": [
    "There are several possible ways to improve sound-based diseases classification:\n",
    "\n",
    "1. Add more audio features.\n",
    "2. Add several channels with various audio features aggregation. Thus, the task can be fully represented as an image classification.\n",
    "3. Add recurrent layers\n",
    "4. Changing dropout.\n",
    "5. Changing sampling rate.\n",
    "6. Use deeper models.\n",
    "7. Audio augmentation to make classification more robust.\n",
    "\n",
    "To orchestrate these experiments MLFlow and Neptune frameworks, for example, can be used. \n",
    "\n",
    "Models calibration is also important here because neural networks tend to be overconfident in their predictions. However, fair calibration requires an additional data subset.\n",
    "\n",
    "From the production point of view, torch models are good because they can be easily converted to one and be inferenced via onnxruntime/onnxruntime server on the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e76f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
